---
layout: post
title: Intro to my research in reinforcement learning
categories: reinforcement Learning
---

## Introduction

Machine learning is usually defined to consist of Supervised Learning and Unsupervised Learning. In supervised learning, a model “learns” a task by training on a set of labeled data. That is, each data point includes the correct “answer” that the model should learn. By doing so, the model is trained to generalize to new, unseen examples. 

Unsupervised learning does not provide labels, and the task then becomes to uncover an underlying structure to the data. 

Reinforcement learning is another pillar of machine learning, and it is a little different than how problems are defined in Supervised and Unsupervised Learning. Problems in reinforcement learning are goal-directed. The goal is to maximize the reward signal given to the reinforcement learning agent in each interaction with an environment.

> The artificial neural network provides the program with the ability to generalize from its experience, so that in new states it selects moves based on information saved from similar states faced in the past, as determined by its network. How well a reinforcement learning system can work in problems with such large sets is intimately tied to how appropriately it can generalize from past experience.


If we want our agent to learn the best sequence of decisions in multiple states through interacting with the environment, then we’ll need to give a value of how much each action will yield a reward. A useful analogy might be that we’re training a person to behave in such a way that their decisions will yield them the most money (reward). Using money as our value metric, we can then compare our choices and decide how to behave.

There’s a theorem that proves that in deterministic environments, there’s at least one optimal policy. However, it might be computationally difficult to assess the value of each policy even in deterministic environments.

### Coming soon...

* Markov Decision Processes - What are they? Why do they matter? 
* Bellman Equations - The Backbone of RL Algorithms
* Q-Learning and Deep Q-Networks
* OpenAI gym API 
* Introducing the Traffic Signaling Problem - Motivations
* Using gym to train a traffic controller with DQN
* DDQN - Extensions
* Multi-Agent Reinforcement Learning - Background


## Previous Presentations
The presentation below was given by me to my Advanced Machine Learning course. I covered the main talking points from my panel presentation at the Eisenhower Fellows Research Panel at the 2019 Transportation Research Board Annual Meeting.
<iframe src="//slides.com/oscastellanos/traffic-signal-controller-a-deep-reinforcement-learning-approach/embed?style=dark" width="576" height="420" scrolling="no" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>

## Notices

**Warning!** This post is being continually updated as the project progresses.
{: .notice}